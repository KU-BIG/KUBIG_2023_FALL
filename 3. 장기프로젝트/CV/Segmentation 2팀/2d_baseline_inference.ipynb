{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c4366358",
      "metadata": {
        "papermill": {
          "duration": 0.006524,
          "end_time": "2023-12-26T15:15:54.638787",
          "exception": false,
          "start_time": "2023-12-26T15:15:54.632263",
          "status": "completed"
        },
        "tags": [],
        "id": "c4366358"
      },
      "source": [
        "# Load Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7235e42a",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2023-12-26T15:15:54.652687Z",
          "iopub.status.busy": "2023-12-26T15:15:54.652027Z",
          "iopub.status.idle": "2023-12-26T15:16:00.687177Z",
          "shell.execute_reply": "2023-12-26T15:16:00.686359Z"
        },
        "papermill": {
          "duration": 6.044661,
          "end_time": "2023-12-26T15:16:00.689518",
          "exception": false,
          "start_time": "2023-12-26T15:15:54.644857",
          "status": "completed"
        },
        "tags": [],
        "id": "7235e42a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "import tifffile as tiff\n",
        "import cv2\n",
        "import torch.nn as nn\n",
        "import albumentations as A\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "from glob import glob\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aaf2ef89",
      "metadata": {
        "papermill": {
          "duration": 0.006129,
          "end_time": "2023-12-26T15:16:00.702141",
          "exception": false,
          "start_time": "2023-12-26T15:16:00.696012",
          "status": "completed"
        },
        "tags": [],
        "id": "aaf2ef89"
      },
      "source": [
        "# Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff070a80",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-26T15:16:00.715320Z",
          "iopub.status.busy": "2023-12-26T15:16:00.714866Z",
          "iopub.status.idle": "2023-12-26T15:16:00.721196Z",
          "shell.execute_reply": "2023-12-26T15:16:00.720365Z"
        },
        "papermill": {
          "duration": 0.015239,
          "end_time": "2023-12-26T15:16:00.723205",
          "exception": false,
          "start_time": "2023-12-26T15:16:00.707966",
          "status": "completed"
        },
        "tags": [],
        "id": "ff070a80"
      },
      "outputs": [],
      "source": [
        "def load_img(path):\n",
        "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
        "    img = np.tile(img[...,None], [1, 1, 3]) # gray to rgb\n",
        "    img = img.astype('float32') # original is uint16\n",
        "    mx = np.max(img)\n",
        "    if mx:\n",
        "        img/=mx # scale image to [0, 1]\n",
        "    return img\n",
        "\n",
        "def load_msk(path):\n",
        "    msk = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
        "    msk = msk.astype('float32')\n",
        "    msk/=255.0\n",
        "    return msk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fceab0a5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-26T15:16:00.736010Z",
          "iopub.status.busy": "2023-12-26T15:16:00.735724Z",
          "iopub.status.idle": "2023-12-26T15:16:00.744658Z",
          "shell.execute_reply": "2023-12-26T15:16:00.743705Z"
        },
        "papermill": {
          "duration": 0.017431,
          "end_time": "2023-12-26T15:16:00.746500",
          "exception": false,
          "start_time": "2023-12-26T15:16:00.729069",
          "status": "completed"
        },
        "tags": [],
        "id": "fceab0a5"
      },
      "outputs": [],
      "source": [
        "class BuildDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, img_paths, msk_paths=[], transforms=None):\n",
        "        self.img_paths  = img_paths\n",
        "        self.msk_paths  = msk_paths\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path  = self.img_paths[index]\n",
        "        img = load_img(img_path)\n",
        "\n",
        "        if len(self.msk_paths)>0:\n",
        "            msk_path = self.msk_paths[index]\n",
        "            msk = load_msk(msk_path)\n",
        "            if self.transforms:\n",
        "                data = self.transforms(image=img, mask=msk)\n",
        "                img  = data['image']\n",
        "                msk  = data['mask']\n",
        "            img = np.transpose(img, (2, 0, 1))\n",
        "            return torch.tensor(img), torch.tensor(msk)\n",
        "        else:\n",
        "            orig_size = img.shape\n",
        "            if self.transforms:\n",
        "                data = self.transforms(image=img)\n",
        "                img  = data['image']\n",
        "            img = np.transpose(img, (2, 0, 1))\n",
        "            return torch.tensor(img), torch.tensor(np.array([orig_size[0], orig_size[1]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a420c10",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-26T15:16:00.759794Z",
          "iopub.status.busy": "2023-12-26T15:16:00.759488Z",
          "iopub.status.idle": "2023-12-26T15:16:00.779465Z",
          "shell.execute_reply": "2023-12-26T15:16:00.778585Z"
        },
        "papermill": {
          "duration": 0.029235,
          "end_time": "2023-12-26T15:16:00.781827",
          "exception": false,
          "start_time": "2023-12-26T15:16:00.752592",
          "status": "completed"
        },
        "tags": [],
        "id": "3a420c10"
      },
      "outputs": [],
      "source": [
        "DATASET_FOLDER = \"/kaggle/input/blood-vessel-segmentation\"\n",
        "ls_images = glob(os.path.join(DATASET_FOLDER, \"test\", \"*\", \"*\", \"*.tif\"))\n",
        "print(f\"found images: {len(ls_images)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37b6368c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-26T15:16:00.795132Z",
          "iopub.status.busy": "2023-12-26T15:16:00.794862Z",
          "iopub.status.idle": "2023-12-26T15:16:00.800169Z",
          "shell.execute_reply": "2023-12-26T15:16:00.799344Z"
        },
        "papermill": {
          "duration": 0.014385,
          "end_time": "2023-12-26T15:16:00.802223",
          "exception": false,
          "start_time": "2023-12-26T15:16:00.787838",
          "status": "completed"
        },
        "tags": [],
        "id": "37b6368c"
      },
      "outputs": [],
      "source": [
        "test_dataset = BuildDataset(ls_images, [], transforms=A.Compose([A.Resize(512,512, interpolation=cv2.INTER_NEAREST)]))\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, num_workers=0, shuffle=False, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddd433bd",
      "metadata": {
        "papermill": {
          "duration": 0.005743,
          "end_time": "2023-12-26T15:16:00.813909",
          "exception": false,
          "start_time": "2023-12-26T15:16:00.808166",
          "status": "completed"
        },
        "tags": [],
        "id": "ddd433bd"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c7b1f8b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-26T15:16:00.827376Z",
          "iopub.status.busy": "2023-12-26T15:16:00.827090Z",
          "iopub.status.idle": "2023-12-26T15:16:00.852445Z",
          "shell.execute_reply": "2023-12-26T15:16:00.851637Z"
        },
        "papermill": {
          "duration": 0.034325,
          "end_time": "2023-12-26T15:16:00.854383",
          "exception": false,
          "start_time": "2023-12-26T15:16:00.820058",
          "status": "completed"
        },
        "tags": [],
        "id": "7c7b1f8b"
      },
      "outputs": [],
      "source": [
        "class ConvBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ConvBlock, self).__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class UpConv(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UpConv, self).__init__()\n",
        "\n",
        "        self.up = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.up(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class AttentionBlock(nn.Module):\n",
        "    \"\"\"Attention block with learnable parameters\"\"\"\n",
        "\n",
        "    def __init__(self, F_g, F_l, n_coefficients):\n",
        "        \"\"\"\n",
        "        :param F_g: number of feature maps (channels) in previous layer\n",
        "        :param F_l: number of feature maps in corresponding encoder layer, transferred via skip connection\n",
        "        :param n_coefficients: number of learnable multi-dimensional attention coefficients\n",
        "        \"\"\"\n",
        "        super(AttentionBlock, self).__init__()\n",
        "\n",
        "        self.W_gate = nn.Sequential(\n",
        "            nn.Conv2d(F_g, n_coefficients, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(n_coefficients)\n",
        "        )\n",
        "\n",
        "        self.W_x = nn.Sequential(\n",
        "            nn.Conv2d(F_l, n_coefficients, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(n_coefficients)\n",
        "        )\n",
        "\n",
        "        self.psi = nn.Sequential(\n",
        "            nn.Conv2d(n_coefficients, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, gate, skip_connection):\n",
        "        \"\"\"\n",
        "        :param gate: gating signal from previous layer\n",
        "        :param skip_connection: activation from corresponding encoder layer\n",
        "        :return: output activations\n",
        "        \"\"\"\n",
        "        g1 = self.W_gate(gate)\n",
        "        x1 = self.W_x(skip_connection)\n",
        "        psi = self.relu(g1 + x1)\n",
        "        psi = self.psi(psi)\n",
        "        out = skip_connection * psi\n",
        "        return out\n",
        "\n",
        "\n",
        "class AttentionUNet(nn.Module):\n",
        "\n",
        "    def __init__(self, img_ch=3, output_ch=1):\n",
        "        super(AttentionUNet, self).__init__()\n",
        "\n",
        "        self.MaxPool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.Conv1 = ConvBlock(img_ch, 64)\n",
        "        self.Conv2 = ConvBlock(64, 128)\n",
        "        self.Conv3 = ConvBlock(128, 256)\n",
        "        self.Conv4 = ConvBlock(256, 512)\n",
        "        self.Conv5 = ConvBlock(512, 1024)\n",
        "\n",
        "        self.Up5 = UpConv(1024, 512)\n",
        "        self.Att5 = AttentionBlock(F_g=512, F_l=512, n_coefficients=256)\n",
        "        self.UpConv5 = ConvBlock(1024, 512)\n",
        "\n",
        "        self.Up4 = UpConv(512, 256)\n",
        "        self.Att4 = AttentionBlock(F_g=256, F_l=256, n_coefficients=128)\n",
        "        self.UpConv4 = ConvBlock(512, 256)\n",
        "\n",
        "        self.Up3 = UpConv(256, 128)\n",
        "        self.Att3 = AttentionBlock(F_g=128, F_l=128, n_coefficients=64)\n",
        "        self.UpConv3 = ConvBlock(256, 128)\n",
        "\n",
        "        self.Up2 = UpConv(128, 64)\n",
        "        self.Att2 = AttentionBlock(F_g=64, F_l=64, n_coefficients=32)\n",
        "        self.UpConv2 = ConvBlock(128, 64)\n",
        "\n",
        "        self.Conv = nn.Conv2d(64, output_ch, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        e : encoder layers\n",
        "        d : decoder layers\n",
        "        s : skip-connections from encoder layers to decoder layers\n",
        "        \"\"\"\n",
        "        e1 = self.Conv1(x)\n",
        "\n",
        "        e2 = self.MaxPool(e1)\n",
        "        e2 = self.Conv2(e2)\n",
        "\n",
        "        e3 = self.MaxPool(e2)\n",
        "        e3 = self.Conv3(e3)\n",
        "\n",
        "        e4 = self.MaxPool(e3)\n",
        "        e4 = self.Conv4(e4)\n",
        "\n",
        "        e5 = self.MaxPool(e4)\n",
        "        e5 = self.Conv5(e5)\n",
        "\n",
        "        d5 = self.Up5(e5)\n",
        "\n",
        "        s4 = self.Att5(gate=d5, skip_connection=e4)\n",
        "        d5 = torch.cat((s4, d5), dim=1)\n",
        "        d5 = self.UpConv5(d5)\n",
        "\n",
        "        d4 = self.Up4(d5)\n",
        "        s3 = self.Att4(gate=d4, skip_connection=e3)\n",
        "        d4 = torch.cat((s3, d4), dim=1)\n",
        "        d4 = self.UpConv4(d4)\n",
        "\n",
        "        d3 = self.Up3(d4)\n",
        "        s2 = self.Att3(gate=d3, skip_connection=e2)\n",
        "        d3 = torch.cat((s2, d3), dim=1)\n",
        "        d3 = self.UpConv3(d3)\n",
        "\n",
        "        d2 = self.Up2(d3)\n",
        "        s1 = self.Att2(gate=d2, skip_connection=e1)\n",
        "        d2 = torch.cat((s1, d2), dim=1)\n",
        "        d2 = self.UpConv2(d2)\n",
        "\n",
        "        out = self.Conv(d2)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1edeaf2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-26T15:16:00.867455Z",
          "iopub.status.busy": "2023-12-26T15:16:00.867176Z",
          "iopub.status.idle": "2023-12-26T15:16:05.350637Z",
          "shell.execute_reply": "2023-12-26T15:16:05.349698Z"
        },
        "papermill": {
          "duration": 4.492408,
          "end_time": "2023-12-26T15:16:05.352783",
          "exception": false,
          "start_time": "2023-12-26T15:16:00.860375",
          "status": "completed"
        },
        "tags": [],
        "id": "d1edeaf2"
      },
      "outputs": [],
      "source": [
        "model = AttentionUNet()\n",
        "model.load_state_dict(torch.load('/kaggle/input/2d-baseline-train/trained_model.pth'))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35f5d0e0",
      "metadata": {
        "papermill": {
          "duration": 0.006297,
          "end_time": "2023-12-26T15:16:05.365616",
          "exception": false,
          "start_time": "2023-12-26T15:16:05.359319",
          "status": "completed"
        },
        "tags": [],
        "id": "35f5d0e0"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7231416",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-26T15:16:05.380447Z",
          "iopub.status.busy": "2023-12-26T15:16:05.380147Z",
          "iopub.status.idle": "2023-12-26T15:16:05.385778Z",
          "shell.execute_reply": "2023-12-26T15:16:05.384900Z"
        },
        "papermill": {
          "duration": 0.014749,
          "end_time": "2023-12-26T15:16:05.387632",
          "exception": false,
          "start_time": "2023-12-26T15:16:05.372883",
          "status": "completed"
        },
        "tags": [],
        "id": "d7231416"
      },
      "outputs": [],
      "source": [
        "def remove_small_objects(img, min_size):\n",
        "    # Find all connected components (labels)\n",
        "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(img, connectivity=8)\n",
        "\n",
        "    # Create a mask where small objects are removed\n",
        "    new_img = np.zeros_like(img)\n",
        "    for label in range(1, num_labels):\n",
        "        if stats[label, cv2.CC_STAT_AREA] >= min_size:\n",
        "            new_img[labels == label] = 1\n",
        "\n",
        "    return new_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb4c665a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-26T15:16:05.401464Z",
          "iopub.status.busy": "2023-12-26T15:16:05.401190Z",
          "iopub.status.idle": "2023-12-26T15:16:05.407293Z",
          "shell.execute_reply": "2023-12-26T15:16:05.406453Z"
        },
        "papermill": {
          "duration": 0.015115,
          "end_time": "2023-12-26T15:16:05.409113",
          "exception": false,
          "start_time": "2023-12-26T15:16:05.393998",
          "status": "completed"
        },
        "tags": [],
        "id": "fb4c665a"
      },
      "outputs": [],
      "source": [
        "def rle_encode(img):\n",
        "    '''\n",
        "    img: numpy array, 1 - mask, 0 - background\n",
        "    Returns run length as string formated\n",
        "    '''\n",
        "    pixels = img.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    rle = ' '.join(str(x) for x in runs)\n",
        "    if rle=='':\n",
        "        rle = '1 0'\n",
        "    return rle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53993efa",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-26T15:16:05.423296Z",
          "iopub.status.busy": "2023-12-26T15:16:05.422598Z",
          "iopub.status.idle": "2023-12-26T15:16:05.481761Z",
          "shell.execute_reply": "2023-12-26T15:16:05.480806Z"
        },
        "papermill": {
          "duration": 0.068433,
          "end_time": "2023-12-26T15:16:05.483884",
          "exception": false,
          "start_time": "2023-12-26T15:16:05.415451",
          "status": "completed"
        },
        "tags": [],
        "id": "53993efa"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e4bed6f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-26T15:16:05.498513Z",
          "iopub.status.busy": "2023-12-26T15:16:05.498203Z",
          "iopub.status.idle": "2023-12-26T15:16:05.502203Z",
          "shell.execute_reply": "2023-12-26T15:16:05.501376Z"
        },
        "papermill": {
          "duration": 0.013461,
          "end_time": "2023-12-26T15:16:05.504065",
          "exception": false,
          "start_time": "2023-12-26T15:16:05.490604",
          "status": "completed"
        },
        "tags": [],
        "id": "5e4bed6f"
      },
      "outputs": [],
      "source": [
        "# model.to('cpu')\n",
        "# preds = model(torch.tensor(np.transpose(A.Compose([A.Resize(256,256, interpolation=cv2.INTER_NEAREST)])(image = load_img('/kaggle/input/blood-vessel-segmentation/train/kidney_1_dense/images/2010.tif'))['image'], (2, 0, 1))).unsqueeze(0))\n",
        "# preds = (nn.Sigmoid()(preds)>0.5).double()\n",
        "# preds.sum()\n",
        "# cv2.resize(preds.numpy()[0], (1303, 912), cv2.INTER_NEAREST).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a53d8b2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-26T15:16:05.518125Z",
          "iopub.status.busy": "2023-12-26T15:16:05.517867Z",
          "iopub.status.idle": "2023-12-26T15:16:05.521960Z",
          "shell.execute_reply": "2023-12-26T15:16:05.521142Z"
        },
        "papermill": {
          "duration": 0.013238,
          "end_time": "2023-12-26T15:16:05.523775",
          "exception": false,
          "start_time": "2023-12-26T15:16:05.510537",
          "status": "completed"
        },
        "tags": [],
        "id": "8a53d8b2"
      },
      "outputs": [],
      "source": [
        "# load_msk('/kaggle/input/blood-vessel-segmentation/train/kidney_1_dense/labels/2010.tif').sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cddab1dd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-26T15:16:05.537613Z",
          "iopub.status.busy": "2023-12-26T15:16:05.537341Z",
          "iopub.status.idle": "2023-12-26T15:16:10.009156Z",
          "shell.execute_reply": "2023-12-26T15:16:10.008024Z"
        },
        "papermill": {
          "duration": 4.481115,
          "end_time": "2023-12-26T15:16:10.011239",
          "exception": false,
          "start_time": "2023-12-26T15:16:05.530124",
          "status": "completed"
        },
        "tags": [],
        "id": "cddab1dd"
      },
      "outputs": [],
      "source": [
        "rles = []\n",
        "pbar = tqdm(enumerate(test_loader), total=len(test_loader), desc='Inference ')\n",
        "for step, (images, shapes) in pbar:\n",
        "    shapes = shapes.numpy()\n",
        "    images = images.to(device, dtype=torch.float)\n",
        "    with torch.no_grad():\n",
        "        preds = model(images)\n",
        "        preds = (nn.Sigmoid()(preds)>0.3).double()\n",
        "    preds = preds.cpu().numpy().astype(np.uint8)\n",
        "\n",
        "    for pred, shape in zip(preds, shapes):\n",
        "        pred = cv2.resize(pred[0], (shape[1], shape[0]), cv2.INTER_NEAREST)\n",
        "        pred = remove_small_objects(pred, 3)\n",
        "        rle = rle_encode(pred)\n",
        "        rles.append(rle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa09e59d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-26T15:16:10.026467Z",
          "iopub.status.busy": "2023-12-26T15:16:10.026156Z",
          "iopub.status.idle": "2023-12-26T15:16:10.031963Z",
          "shell.execute_reply": "2023-12-26T15:16:10.031073Z"
        },
        "papermill": {
          "duration": 0.015568,
          "end_time": "2023-12-26T15:16:10.033761",
          "exception": false,
          "start_time": "2023-12-26T15:16:10.018193",
          "status": "completed"
        },
        "tags": [],
        "id": "aa09e59d"
      },
      "outputs": [],
      "source": [
        "rles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b478b1a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-26T15:16:10.049215Z",
          "iopub.status.busy": "2023-12-26T15:16:10.048622Z",
          "iopub.status.idle": "2023-12-26T15:16:10.056597Z",
          "shell.execute_reply": "2023-12-26T15:16:10.055681Z"
        },
        "papermill": {
          "duration": 0.018024,
          "end_time": "2023-12-26T15:16:10.058787",
          "exception": false,
          "start_time": "2023-12-26T15:16:10.040763",
          "status": "completed"
        },
        "tags": [],
        "id": "8b478b1a"
      },
      "outputs": [],
      "source": [
        "ids = []\n",
        "for p_img in tqdm(ls_images):\n",
        "    path_ = p_img.split(os.path.sep)\n",
        "    # parse the submission ID\n",
        "    dataset = path_[-3]\n",
        "    slice_id, _ = os.path.splitext(path_[-1])\n",
        "    ids.append(f\"{dataset}_{slice_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4516f083",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-26T15:16:10.074933Z",
          "iopub.status.busy": "2023-12-26T15:16:10.074545Z",
          "iopub.status.idle": "2023-12-26T15:16:10.086555Z",
          "shell.execute_reply": "2023-12-26T15:16:10.085815Z"
        },
        "papermill": {
          "duration": 0.022607,
          "end_time": "2023-12-26T15:16:10.088599",
          "exception": false,
          "start_time": "2023-12-26T15:16:10.065992",
          "status": "completed"
        },
        "tags": [],
        "id": "4516f083"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame.from_dict({\n",
        "    \"id\": ids,\n",
        "    \"rle\": rles\n",
        "})\n",
        "submission.to_csv(\"submission.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71792ee8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-26T15:16:10.105213Z",
          "iopub.status.busy": "2023-12-26T15:16:10.104873Z",
          "iopub.status.idle": "2023-12-26T15:16:10.121610Z",
          "shell.execute_reply": "2023-12-26T15:16:10.120473Z"
        },
        "papermill": {
          "duration": 0.029766,
          "end_time": "2023-12-26T15:16:10.126013",
          "exception": false,
          "start_time": "2023-12-26T15:16:10.096247",
          "status": "completed"
        },
        "tags": [],
        "id": "71792ee8"
      },
      "outputs": [],
      "source": [
        "submission"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "databundleVersionId": 6962461,
          "sourceId": 61446,
          "sourceType": "competition"
        },
        {
          "sourceId": 156031721,
          "sourceType": "kernelVersion"
        }
      ],
      "dockerImageVersionId": 30616,
      "isGpuEnabled": true,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 21.478405,
      "end_time": "2023-12-26T15:16:12.785965",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-12-26T15:15:51.307560",
      "version": "2.4.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}