{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "56ac94f2",
      "metadata": {
        "papermill": {
          "duration": 0.009856,
          "end_time": "2023-12-22T07:29:39.063179",
          "exception": false,
          "start_time": "2023-12-22T07:29:39.053323",
          "status": "completed"
        },
        "tags": [],
        "id": "56ac94f2"
      },
      "source": [
        "# SenNet + HOA - Hacking the Human Vasculature in 3D"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fec4161",
      "metadata": {
        "papermill": {
          "duration": 0.008909,
          "end_time": "2023-12-22T07:29:39.081484",
          "exception": false,
          "start_time": "2023-12-22T07:29:39.072575",
          "status": "completed"
        },
        "tags": [],
        "id": "7fec4161"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e0b300a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-22T07:29:39.101323Z",
          "iopub.status.busy": "2023-12-22T07:29:39.100970Z",
          "iopub.status.idle": "2023-12-22T07:29:44.841672Z",
          "shell.execute_reply": "2023-12-22T07:29:44.840869Z"
        },
        "papermill": {
          "duration": 5.753388,
          "end_time": "2023-12-22T07:29:44.844076",
          "exception": false,
          "start_time": "2023-12-22T07:29:39.090688",
          "status": "completed"
        },
        "tags": [],
        "id": "8e0b300a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "import tifffile as tiff\n",
        "import cv2\n",
        "import torch.nn as nn\n",
        "import albumentations as A\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70203edb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-22T07:29:44.864930Z",
          "iopub.status.busy": "2023-12-22T07:29:44.864541Z",
          "iopub.status.idle": "2023-12-22T07:29:45.833488Z",
          "shell.execute_reply": "2023-12-22T07:29:45.832372Z"
        },
        "papermill": {
          "duration": 0.981744,
          "end_time": "2023-12-22T07:29:45.835724",
          "exception": false,
          "start_time": "2023-12-22T07:29:44.853980",
          "status": "completed"
        },
        "tags": [],
        "id": "70203edb"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fb49b60",
      "metadata": {
        "papermill": {
          "duration": 0.009148,
          "end_time": "2023-12-22T07:29:45.854650",
          "exception": false,
          "start_time": "2023-12-22T07:29:45.845502",
          "status": "completed"
        },
        "tags": [],
        "id": "0fb49b60"
      },
      "source": [
        "## Sample Original Image & Label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fd56c82",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-22T07:29:45.874711Z",
          "iopub.status.busy": "2023-12-22T07:29:45.874388Z",
          "iopub.status.idle": "2023-12-22T07:29:46.947998Z",
          "shell.execute_reply": "2023-12-22T07:29:46.947051Z"
        },
        "papermill": {
          "duration": 1.092101,
          "end_time": "2023-12-22T07:29:46.956064",
          "exception": false,
          "start_time": "2023-12-22T07:29:45.863963",
          "status": "completed"
        },
        "tags": [],
        "id": "3fd56c82"
      },
      "outputs": [],
      "source": [
        "base_path = '/kaggle/input/blood-vessel-segmentation/train'\n",
        "\n",
        "dataset = 'kidney_1_dense'\n",
        "\n",
        "datasets = ['kidney_1_dense',\n",
        " 'kidney_1_voi',\n",
        " 'kidney_2',\n",
        " 'kidney_3_dense',\n",
        " 'kidney_3_sparse']\n",
        "\n",
        "images_path = os.path.join(base_path, dataset, 'images')\n",
        "labels_path = os.path.join(base_path, dataset, 'labels')\n",
        "\n",
        "image_files = sorted([os.path.join(images_path, f) for f in os.listdir(images_path) if f.endswith('.tif')])\n",
        "label_files = sorted([os.path.join(labels_path, f) for f in os.listdir(labels_path) if f.endswith('.tif')])\n",
        "\n",
        "\n",
        "def show_images(images,titles= None, cmap='gray'):\n",
        "    n = len(images)\n",
        "    fig, axes = plt.subplots(1, n, figsize=(20, 10))\n",
        "    if not isinstance(axes, np.ndarray):\n",
        "        axes = [axes]\n",
        "    for idx, ax in enumerate(axes):\n",
        "        ax.imshow(images[idx], cmap=cmap)\n",
        "        if titles:\n",
        "            ax.set_title(titles[idx])\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "ex_image = tiff.imread(image_files[800])\n",
        "ex_label = tiff.imread(label_files[800])\n",
        "\n",
        "show_images([ex_image, ex_label], titles=['ex Image', 'ex Label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1adf6b2f",
      "metadata": {
        "papermill": {
          "duration": 0.018304,
          "end_time": "2023-12-22T07:29:46.993263",
          "exception": false,
          "start_time": "2023-12-22T07:29:46.974959",
          "status": "completed"
        },
        "tags": [],
        "id": "1adf6b2f"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe5323f4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-22T07:29:47.031467Z",
          "iopub.status.busy": "2023-12-22T07:29:47.030892Z",
          "iopub.status.idle": "2023-12-22T07:29:47.037751Z",
          "shell.execute_reply": "2023-12-22T07:29:47.036936Z"
        },
        "papermill": {
          "duration": 0.028048,
          "end_time": "2023-12-22T07:29:47.039676",
          "exception": false,
          "start_time": "2023-12-22T07:29:47.011628",
          "status": "completed"
        },
        "tags": [],
        "id": "fe5323f4"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image_files, mask_files, input_size=(256, 256), augmentation_transforms=None):\n",
        "        self.image_files = image_files\n",
        "        self.mask_files = mask_files\n",
        "        self.input_size = input_size\n",
        "        self.augmentation_transforms = augmentation_transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        image_path = self.image_files[idx]\n",
        "        mask_path = self.mask_files[idx]\n",
        "\n",
        "        image = preprocess_image(image_path)\n",
        "        mask = preprocess_mask(mask_path)\n",
        "\n",
        "        if self.augmentation_transforms:\n",
        "            image, mask = self.augmentation_transforms(image, mask)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e97141a",
      "metadata": {
        "papermill": {
          "duration": 0.018263,
          "end_time": "2023-12-22T07:29:47.076261",
          "exception": false,
          "start_time": "2023-12-22T07:29:47.057998",
          "status": "completed"
        },
        "tags": [],
        "id": "3e97141a"
      },
      "source": [
        "## Preprocessing of Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "172d638d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-22T07:29:47.113910Z",
          "iopub.status.busy": "2023-12-22T07:29:47.113648Z",
          "iopub.status.idle": "2023-12-22T07:29:47.119304Z",
          "shell.execute_reply": "2023-12-22T07:29:47.118463Z"
        },
        "papermill": {
          "duration": 0.026859,
          "end_time": "2023-12-22T07:29:47.121278",
          "exception": false,
          "start_time": "2023-12-22T07:29:47.094419",
          "status": "completed"
        },
        "tags": [],
        "id": "172d638d"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(path):\n",
        "\n",
        "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)  # read tif image files. 원본 그대로 읽어오기 위한 imread_unchanged flag 추가, shape (1303, 912)\n",
        "    img = np.tile(img[...,None],[1, 1, 3])\n",
        "    img = img.astype('float32')\n",
        "    mx = np.max(img)\n",
        "    if mx:\n",
        "        img/=mx\n",
        "\n",
        "    img = np.transpose(img, (2, 0, 1))\n",
        "    img_ten = torch.tensor(img)\n",
        "    return img_ten"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d0b6e30",
      "metadata": {
        "papermill": {
          "duration": 0.018439,
          "end_time": "2023-12-22T07:29:47.158452",
          "exception": false,
          "start_time": "2023-12-22T07:29:47.140013",
          "status": "completed"
        },
        "tags": [],
        "id": "1d0b6e30"
      },
      "source": [
        "## Preprocessing of Masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "027a997a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-22T07:29:47.197087Z",
          "iopub.status.busy": "2023-12-22T07:29:47.196799Z",
          "iopub.status.idle": "2023-12-22T07:29:47.201407Z",
          "shell.execute_reply": "2023-12-22T07:29:47.200656Z"
        },
        "papermill": {
          "duration": 0.026289,
          "end_time": "2023-12-22T07:29:47.203207",
          "exception": false,
          "start_time": "2023-12-22T07:29:47.176918",
          "status": "completed"
        },
        "tags": [],
        "id": "027a997a"
      },
      "outputs": [],
      "source": [
        "def preprocess_mask(path):\n",
        "\n",
        "    msk = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
        "    msk = msk.astype('float32')\n",
        "    msk/=255.0\n",
        "    msk_ten = torch.tensor(msk)\n",
        "\n",
        "    return msk_ten"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caae90a0",
      "metadata": {
        "papermill": {
          "duration": 0.018412,
          "end_time": "2023-12-22T07:29:47.239924",
          "exception": false,
          "start_time": "2023-12-22T07:29:47.221512",
          "status": "completed"
        },
        "tags": [],
        "id": "caae90a0"
      },
      "source": [
        "## Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a64a114",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-22T07:29:47.279131Z",
          "iopub.status.busy": "2023-12-22T07:29:47.278856Z",
          "iopub.status.idle": "2023-12-22T07:29:47.287102Z",
          "shell.execute_reply": "2023-12-22T07:29:47.286335Z"
        },
        "papermill": {
          "duration": 0.029897,
          "end_time": "2023-12-22T07:29:47.289000",
          "exception": false,
          "start_time": "2023-12-22T07:29:47.259103",
          "status": "completed"
        },
        "tags": [],
        "id": "1a64a114"
      },
      "outputs": [],
      "source": [
        "def augment_image(image, mask):\n",
        "\n",
        "    image_np = image.permute(1, 2, 0).numpy()\n",
        "    mask_np = mask.numpy()\n",
        "\n",
        "    transform = A.Compose([\n",
        "        A.Resize(512,512, interpolation=cv2.INTER_NEAREST),\n",
        "        A.HorizontalFlip(p=0.3),\n",
        "        A.VerticalFlip(p=0.2),\n",
        "        A.ShiftScaleRotate(scale_limit=0.3, rotate_limit=0, shift_limit=0.1, p=1, border_mode=0),\n",
        "#         A.RandomCrop(height=256, width=256, always_apply=True),\n",
        "        A.RandomBrightnessContrast(p=0.5),\n",
        "        A.OneOf(\n",
        "            [\n",
        "                A.Blur(blur_limit=3, p=0.7),\n",
        "                A.MotionBlur(blur_limit=3, p=0.7),\n",
        "            ],\n",
        "            p=0.5,\n",
        "        ),\n",
        "\n",
        "    ])\n",
        "\n",
        "    augmented = transform(image=image_np, mask=mask_np)\n",
        "    augmented_image, augmented_mask = augmented['image'], augmented['mask']\n",
        "\n",
        "    augmented_image = torch.tensor(augmented_image, dtype=torch.float32).permute(2, 0, 1)\n",
        "    augmented_mask = torch.tensor(augmented_mask, dtype=torch.float32)\n",
        "\n",
        "    return augmented_image, augmented_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af2117da",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-22T07:29:47.326968Z",
          "iopub.status.busy": "2023-12-22T07:29:47.326703Z",
          "iopub.status.idle": "2023-12-22T07:29:47.334772Z",
          "shell.execute_reply": "2023-12-22T07:29:47.334110Z"
        },
        "papermill": {
          "duration": 0.029236,
          "end_time": "2023-12-22T07:29:47.336663",
          "exception": false,
          "start_time": "2023-12-22T07:29:47.307427",
          "status": "completed"
        },
        "tags": [],
        "id": "af2117da"
      },
      "outputs": [],
      "source": [
        "sorted(os.listdir(base_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b1cf812",
      "metadata": {
        "papermill": {
          "duration": 0.018186,
          "end_time": "2023-12-22T07:29:47.373306",
          "exception": false,
          "start_time": "2023-12-22T07:29:47.355120",
          "status": "completed"
        },
        "tags": [],
        "id": "7b1cf812"
      },
      "source": [
        "## Splitting the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cae7f20",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-22T07:29:47.411708Z",
          "iopub.status.busy": "2023-12-22T07:29:47.411440Z",
          "iopub.status.idle": "2023-12-22T07:29:47.831630Z",
          "shell.execute_reply": "2023-12-22T07:29:47.830672Z"
        },
        "papermill": {
          "duration": 0.442082,
          "end_time": "2023-12-22T07:29:47.834163",
          "exception": false,
          "start_time": "2023-12-22T07:29:47.392081",
          "status": "completed"
        },
        "tags": [],
        "id": "0cae7f20"
      },
      "outputs": [],
      "source": [
        "base_path = '/kaggle/input/blood-vessel-segmentation/train'\n",
        "\n",
        "datasets = ['kidney_1_dense',\n",
        " 'kidney_1_voi',\n",
        " 'kidney_2',\n",
        " 'kidney_3_dense',\n",
        " 'kidney_3_sparse']\n",
        "\n",
        "image_files = []\n",
        "label_files = []\n",
        "\n",
        "for dataset in datasets :\n",
        "    if dataset != 'kidney_3_dense' :\n",
        "        image_path = os.path.join(base_path, dataset, 'images')\n",
        "        label_path = os.path.join(base_path, dataset, 'labels')\n",
        "\n",
        "    else:\n",
        "        image_path = os.path.join(base_path, 'kidney_3_sparse', 'images')\n",
        "        label_path = os.path.join(base_path, dataset, 'labels')\n",
        "\n",
        "    image_files.extend(sorted([os.path.join(image_path, f) for f in os.listdir(label_path) if f.endswith('.tif')]))\n",
        "    label_files.extend(sorted([os.path.join(label_path, f) for f in os.listdir(label_path) if f.endswith('.tif')]))\n",
        "\n",
        "len(image_files), len(label_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "993df8ce",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-22T07:29:47.873719Z",
          "iopub.status.busy": "2023-12-22T07:29:47.873442Z",
          "iopub.status.idle": "2023-12-22T07:29:47.882401Z",
          "shell.execute_reply": "2023-12-22T07:29:47.881727Z"
        },
        "papermill": {
          "duration": 0.030454,
          "end_time": "2023-12-22T07:29:47.884240",
          "exception": false,
          "start_time": "2023-12-22T07:29:47.853786",
          "status": "completed"
        },
        "tags": [],
        "id": "993df8ce"
      },
      "outputs": [],
      "source": [
        "train_image_files, val_image_files, train_mask_files, val_mask_files = train_test_split(\n",
        "    image_files, label_files, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e4359b6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-22T07:29:47.922582Z",
          "iopub.status.busy": "2023-12-22T07:29:47.922329Z",
          "iopub.status.idle": "2023-12-22T07:29:47.926585Z",
          "shell.execute_reply": "2023-12-22T07:29:47.925752Z"
        },
        "papermill": {
          "duration": 0.025679,
          "end_time": "2023-12-22T07:29:47.928391",
          "exception": false,
          "start_time": "2023-12-22T07:29:47.902712",
          "status": "completed"
        },
        "tags": [],
        "id": "4e4359b6"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomDataset(train_image_files, train_mask_files, augmentation_transforms=augment_image)\n",
        "val_dataset = CustomDataset(val_image_files, val_mask_files, augmentation_transforms=augment_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf4aefee",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-22T07:29:47.966680Z",
          "iopub.status.busy": "2023-12-22T07:29:47.966412Z",
          "iopub.status.idle": "2023-12-22T07:29:47.970928Z",
          "shell.execute_reply": "2023-12-22T07:29:47.970188Z"
        },
        "papermill": {
          "duration": 0.025846,
          "end_time": "2023-12-22T07:29:47.972749",
          "exception": false,
          "start_time": "2023-12-22T07:29:47.946903",
          "status": "completed"
        },
        "tags": [],
        "id": "bf4aefee"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=6, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=6, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f97b07a7",
      "metadata": {
        "papermill": {
          "duration": 0.018312,
          "end_time": "2023-12-22T07:29:48.009637",
          "exception": false,
          "start_time": "2023-12-22T07:29:47.991325",
          "status": "completed"
        },
        "tags": [],
        "id": "f97b07a7"
      },
      "source": [
        "## Augmented Batch_1 Images & Labels Viz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fccdcbd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-22T07:29:48.047688Z",
          "iopub.status.busy": "2023-12-22T07:29:48.047442Z",
          "iopub.status.idle": "2023-12-22T07:29:48.051940Z",
          "shell.execute_reply": "2023-12-22T07:29:48.051179Z"
        },
        "papermill": {
          "duration": 0.025726,
          "end_time": "2023-12-22T07:29:48.053799",
          "exception": false,
          "start_time": "2023-12-22T07:29:48.028073",
          "status": "completed"
        },
        "tags": [],
        "id": "4fccdcbd"
      },
      "outputs": [],
      "source": [
        "# for batch_idx, (batch_images, batch_masks) in enumerate(train_dataloader):\n",
        "#     print(\"Batch\", batch_idx + 1)\n",
        "#     print(\"Image batch shape:\", batch_images.shape)\n",
        "#     print(\"Mask batch shape:\", batch_masks.shape)\n",
        "\n",
        "#     for image, mask, image_path, mask_path in zip(batch_images, batch_masks, train_image_files, train_mask_files):\n",
        "\n",
        "#         image = image.permute((1, 2, 0)).numpy()*255.0\n",
        "#         image = image.astype('uint8')\n",
        "#         mask = (mask*255).numpy().astype('uint8')\n",
        "\n",
        "#         image_filename = os.path.basename(image_path)\n",
        "#         mask_filename = os.path.basename(mask_path)\n",
        "\n",
        "#         plt.figure(figsize=(15, 10))\n",
        "\n",
        "#         plt.subplot(2, 4, 1)\n",
        "#         plt.imshow(image, cmap='gray')\n",
        "#         plt.title(f\"Original Image - {image_filename}\")\n",
        "\n",
        "#         plt.subplot(2, 4, 2)\n",
        "#         plt.imshow(mask, cmap='gray')\n",
        "#         plt.title(f\"Mask Image - {mask_filename}\")\n",
        "\n",
        "#         plt.tight_layout()\n",
        "#         plt.show()\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7eab3220",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-22T07:29:48.092139Z",
          "iopub.status.busy": "2023-12-22T07:29:48.091871Z",
          "iopub.status.idle": "2023-12-22T07:29:48.095418Z",
          "shell.execute_reply": "2023-12-22T07:29:48.094662Z"
        },
        "papermill": {
          "duration": 0.024707,
          "end_time": "2023-12-22T07:29:48.097283",
          "exception": false,
          "start_time": "2023-12-22T07:29:48.072576",
          "status": "completed"
        },
        "tags": [],
        "id": "7eab3220"
      },
      "outputs": [],
      "source": [
        "# for batch_idx, (batch_images, batch_masks) in enumerate(train_dataloader):\n",
        "#     print(\"Batch\", batch_idx + 1)\n",
        "#     print(\"Image batch shape:\", batch_images.shape)\n",
        "#     print(\"Mask batch shape:\", batch_masks.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f73ab14",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-22T07:29:48.136331Z",
          "iopub.status.busy": "2023-12-22T07:29:48.135626Z",
          "iopub.status.idle": "2023-12-22T07:29:48.139711Z",
          "shell.execute_reply": "2023-12-22T07:29:48.138993Z"
        },
        "papermill": {
          "duration": 0.025575,
          "end_time": "2023-12-22T07:29:48.141557",
          "exception": false,
          "start_time": "2023-12-22T07:29:48.115982",
          "status": "completed"
        },
        "tags": [],
        "id": "9f73ab14"
      },
      "outputs": [],
      "source": [
        "# for batch_idx, (batch_images, batch_masks) in enumerate(val_dataloader):\n",
        "#     print(\"Batch\", batch_idx + 1)\n",
        "#     print(\"Image batch shape:\", batch_images.shape)\n",
        "#     print(\"Mask batch shape:\", batch_masks.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23bb6f20",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-22T07:29:48.179711Z",
          "iopub.status.busy": "2023-12-22T07:29:48.179450Z",
          "iopub.status.idle": "2023-12-22T07:29:48.252861Z",
          "shell.execute_reply": "2023-12-22T07:29:48.251998Z"
        },
        "papermill": {
          "duration": 0.094774,
          "end_time": "2023-12-22T07:29:48.254785",
          "exception": false,
          "start_time": "2023-12-22T07:29:48.160011",
          "status": "completed"
        },
        "tags": [],
        "id": "23bb6f20"
      },
      "outputs": [],
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "device = get_default_device()\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4cbb24a",
      "metadata": {
        "papermill": {
          "duration": 0.05983,
          "end_time": "2023-12-22T07:29:48.333961",
          "exception": false,
          "start_time": "2023-12-22T07:29:48.274131",
          "status": "completed"
        },
        "tags": [],
        "id": "f4cbb24a"
      },
      "source": [
        "## Attention U-Net architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5b4b735",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-22T07:29:48.373351Z",
          "iopub.status.busy": "2023-12-22T07:29:48.372725Z",
          "iopub.status.idle": "2023-12-22T07:29:48.399413Z",
          "shell.execute_reply": "2023-12-22T07:29:48.398570Z"
        },
        "papermill": {
          "duration": 0.048364,
          "end_time": "2023-12-22T07:29:48.401240",
          "exception": false,
          "start_time": "2023-12-22T07:29:48.352876",
          "status": "completed"
        },
        "tags": [],
        "id": "b5b4b735"
      },
      "outputs": [],
      "source": [
        "class ConvBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ConvBlock, self).__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class UpConv(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UpConv, self).__init__()\n",
        "\n",
        "        self.up = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.up(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class AttentionBlock(nn.Module):\n",
        "    \"\"\"Attention block with learnable parameters\"\"\"\n",
        "\n",
        "    def __init__(self, F_g, F_l, n_coefficients):\n",
        "        \"\"\"\n",
        "        :param F_g: number of feature maps (channels) in previous layer\n",
        "        :param F_l: number of feature maps in corresponding encoder layer, transferred via skip connection\n",
        "        :param n_coefficients: number of learnable multi-dimensional attention coefficients\n",
        "        \"\"\"\n",
        "        super(AttentionBlock, self).__init__()\n",
        "\n",
        "        self.W_gate = nn.Sequential(\n",
        "            nn.Conv2d(F_g, n_coefficients, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(n_coefficients)\n",
        "        )\n",
        "\n",
        "        self.W_x = nn.Sequential(\n",
        "            nn.Conv2d(F_l, n_coefficients, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(n_coefficients)\n",
        "        )\n",
        "\n",
        "        self.psi = nn.Sequential(\n",
        "            nn.Conv2d(n_coefficients, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, gate, skip_connection):\n",
        "        \"\"\"\n",
        "        :param gate: gating signal from previous layer\n",
        "        :param skip_connection: activation from corresponding encoder layer\n",
        "        :return: output activations\n",
        "        \"\"\"\n",
        "        g1 = self.W_gate(gate)\n",
        "        x1 = self.W_x(skip_connection)\n",
        "        psi = self.relu(g1 + x1)\n",
        "        psi = self.psi(psi)\n",
        "        out = skip_connection * psi\n",
        "        return out\n",
        "\n",
        "\n",
        "class AttentionUNet(nn.Module):\n",
        "\n",
        "    def __init__(self, img_ch=3, output_ch=1):\n",
        "        super(AttentionUNet, self).__init__()\n",
        "\n",
        "        self.MaxPool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.Conv1 = ConvBlock(img_ch, 64)\n",
        "        self.Conv2 = ConvBlock(64, 128)\n",
        "        self.Conv3 = ConvBlock(128, 256)\n",
        "        self.Conv4 = ConvBlock(256, 512)\n",
        "        self.Conv5 = ConvBlock(512, 1024)\n",
        "\n",
        "        self.Up5 = UpConv(1024, 512)\n",
        "        self.Att5 = AttentionBlock(F_g=512, F_l=512, n_coefficients=256)\n",
        "        self.UpConv5 = ConvBlock(1024, 512)\n",
        "\n",
        "        self.Up4 = UpConv(512, 256)\n",
        "        self.Att4 = AttentionBlock(F_g=256, F_l=256, n_coefficients=128)\n",
        "        self.UpConv4 = ConvBlock(512, 256)\n",
        "\n",
        "        self.Up3 = UpConv(256, 128)\n",
        "        self.Att3 = AttentionBlock(F_g=128, F_l=128, n_coefficients=64)\n",
        "        self.UpConv3 = ConvBlock(256, 128)\n",
        "\n",
        "        self.Up2 = UpConv(128, 64)\n",
        "        self.Att2 = AttentionBlock(F_g=64, F_l=64, n_coefficients=32)\n",
        "        self.UpConv2 = ConvBlock(128, 64)\n",
        "\n",
        "        self.Conv = nn.Conv2d(64, output_ch, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        e : encoder layers\n",
        "        d : decoder layers\n",
        "        s : skip-connections from encoder layers to decoder layers\n",
        "        \"\"\"\n",
        "        e1 = self.Conv1(x)\n",
        "\n",
        "        e2 = self.MaxPool(e1)\n",
        "        e2 = self.Conv2(e2)\n",
        "\n",
        "        e3 = self.MaxPool(e2)\n",
        "        e3 = self.Conv3(e3)\n",
        "\n",
        "        e4 = self.MaxPool(e3)\n",
        "        e4 = self.Conv4(e4)\n",
        "\n",
        "        e5 = self.MaxPool(e4)\n",
        "        e5 = self.Conv5(e5)\n",
        "\n",
        "        d5 = self.Up5(e5)\n",
        "\n",
        "        s4 = self.Att5(gate=d5, skip_connection=e4)\n",
        "        d5 = torch.cat((s4, d5), dim=1)\n",
        "        d5 = self.UpConv5(d5)\n",
        "\n",
        "        d4 = self.Up4(d5)\n",
        "        s3 = self.Att4(gate=d4, skip_connection=e3)\n",
        "        d4 = torch.cat((s3, d4), dim=1)\n",
        "        d4 = self.UpConv4(d4)\n",
        "\n",
        "        d3 = self.Up3(d4)\n",
        "        s2 = self.Att3(gate=d3, skip_connection=e2)\n",
        "        d3 = torch.cat((s2, d3), dim=1)\n",
        "        d3 = self.UpConv3(d3)\n",
        "\n",
        "        d2 = self.Up2(d3)\n",
        "        s1 = self.Att2(gate=d2, skip_connection=e1)\n",
        "        d2 = torch.cat((s1, d2), dim=1)\n",
        "        d2 = self.UpConv2(d2)\n",
        "\n",
        "        out = self.Conv(d2)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bfb7778",
      "metadata": {
        "papermill": {
          "duration": 0.018574,
          "end_time": "2023-12-22T07:29:48.439116",
          "exception": false,
          "start_time": "2023-12-22T07:29:48.420542",
          "status": "completed"
        },
        "tags": [],
        "id": "5bfb7778"
      },
      "source": [
        "## Dice Coefficient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daffe6e3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-22T07:29:48.477786Z",
          "iopub.status.busy": "2023-12-22T07:29:48.477505Z",
          "iopub.status.idle": "2023-12-22T07:29:48.482599Z",
          "shell.execute_reply": "2023-12-22T07:29:48.481792Z"
        },
        "papermill": {
          "duration": 0.026517,
          "end_time": "2023-12-22T07:29:48.484476",
          "exception": false,
          "start_time": "2023-12-22T07:29:48.457959",
          "status": "completed"
        },
        "tags": [],
        "id": "daffe6e3"
      },
      "outputs": [],
      "source": [
        "def dice_coeff(prediction, target):\n",
        "\n",
        "    mask = np.zeros_like(prediction)\n",
        "    mask[prediction >= 0.5] = 1\n",
        "\n",
        "    inter = np.sum(mask * target)\n",
        "    union = np.sum(mask) + np.sum(target)\n",
        "    epsilon = 1e-6\n",
        "    result = np.mean(2 * inter / (union + epsilon))\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2bd9ba6",
      "metadata": {
        "papermill": {
          "duration": 0.01863,
          "end_time": "2023-12-22T07:29:48.521887",
          "exception": false,
          "start_time": "2023-12-22T07:29:48.503257",
          "status": "completed"
        },
        "tags": [],
        "id": "e2bd9ba6"
      },
      "source": [
        "## Focal Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abd69237",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-22T07:29:48.561166Z",
          "iopub.status.busy": "2023-12-22T07:29:48.560885Z",
          "iopub.status.idle": "2023-12-22T07:29:48.568271Z",
          "shell.execute_reply": "2023-12-22T07:29:48.567511Z"
        },
        "papermill": {
          "duration": 0.029088,
          "end_time": "2023-12-22T07:29:48.570131",
          "exception": false,
          "start_time": "2023-12-22T07:29:48.541043",
          "status": "completed"
        },
        "tags": [],
        "id": "abd69237"
      },
      "outputs": [],
      "source": [
        "class FocalLoss(nn.modules.loss._WeightedLoss):\n",
        "\n",
        "    def __init__(self, gamma=0, size_average=None, ignore_index=-100,\n",
        "                 reduce=None, balance_param=1.0):\n",
        "        super(FocalLoss, self).__init__(size_average)\n",
        "        self.gamma = gamma\n",
        "        self.size_average = size_average\n",
        "        self.ignore_index = ignore_index\n",
        "        self.balance_param = balance_param\n",
        "\n",
        "    def forward(self, input, target):\n",
        "\n",
        "        assert len(input.shape) == len(target.shape)\n",
        "        assert input.size(0) == target.size(0)\n",
        "        assert input.size(1) == target.size(1)\n",
        "\n",
        "        logpt = - F.binary_cross_entropy_with_logits(input, target)\n",
        "        pt = torch.exp(logpt)\n",
        "\n",
        "        focal_loss = -((1 - pt) ** self.gamma) * logpt\n",
        "        balanced_focal_loss = self.balance_param * focal_loss\n",
        "        return balanced_focal_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adbdca9c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-22T07:29:48.608570Z",
          "iopub.status.busy": "2023-12-22T07:29:48.608304Z",
          "iopub.status.idle": "2023-12-22T07:29:48.612208Z",
          "shell.execute_reply": "2023-12-22T07:29:48.611387Z"
        },
        "papermill": {
          "duration": 0.02518,
          "end_time": "2023-12-22T07:29:48.614086",
          "exception": false,
          "start_time": "2023-12-22T07:29:48.588906",
          "status": "completed"
        },
        "tags": [],
        "id": "adbdca9c"
      },
      "outputs": [],
      "source": [
        "dataloaders = {\n",
        "    'training': train_dataloader,\n",
        "    'test': val_dataloader\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65e6588b",
      "metadata": {
        "papermill": {
          "duration": 0.019424,
          "end_time": "2023-12-22T07:29:48.652197",
          "exception": false,
          "start_time": "2023-12-22T07:29:48.632773",
          "status": "completed"
        },
        "tags": [],
        "id": "65e6588b"
      },
      "source": [
        "## Training and Testing Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05d4d66c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-22T07:29:48.691178Z",
          "iopub.status.busy": "2023-12-22T07:29:48.690659Z",
          "iopub.status.idle": "2023-12-22T07:29:48.786164Z",
          "shell.execute_reply": "2023-12-22T07:29:48.785314Z"
        },
        "papermill": {
          "duration": 0.117327,
          "end_time": "2023-12-22T07:29:48.788240",
          "exception": false,
          "start_time": "2023-12-22T07:29:48.670913",
          "status": "completed"
        },
        "tags": [],
        "id": "05d4d66c"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import trange\n",
        "\n",
        "def train_and_test(model, dataloaders, optimizer, criterion, num_epochs=100, show_images=False):\n",
        "    since = time.time()\n",
        "    best_loss = 1e10\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    fieldnames = ['epoch', 'training_loss', 'test_loss', 'training_dice_coeff', 'test_dice_coeff']\n",
        "    train_epoch_losses = []\n",
        "    test_epoch_losses = []\n",
        "    for epoch in trange(1, num_epochs + 1):\n",
        "\n",
        "        print(f'Epoch {epoch}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        batchsummary = {a: [0] for a in fieldnames}\n",
        "        batch_train_loss = 0.0\n",
        "        batch_test_loss = 0.0\n",
        "\n",
        "        for phase in ['training', 'test']:\n",
        "            if phase == 'training':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            for sample in iter(dataloaders[phase]):\n",
        "\n",
        "                if show_images:\n",
        "                    grid_img = make_grid(sample[0])\n",
        "                    grid_img = grid_img.permute(1, 2, 0)\n",
        "                    plt.imshow(grid_img)\n",
        "                    plt.show()\n",
        "\n",
        "                inputs = sample[0].to(device)\n",
        "                masks = sample[1].to(device)\n",
        "\n",
        "                masks = masks.unsqueeze(1)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'training'):\n",
        "                    outputs = model(inputs)\n",
        "\n",
        "                    loss = criterion(outputs, masks)\n",
        "\n",
        "                    y_pred = outputs.data.cpu().numpy().ravel()\n",
        "                    y_true = masks.data.cpu().numpy().ravel()\n",
        "\n",
        "                    batchsummary[f'{phase}_dice_coeff'].append(dice_coeff(y_pred, y_true))\n",
        "\n",
        "                    if phase == 'training':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                        batch_train_loss += loss.item() * sample[0].size(0)\n",
        "\n",
        "                    else:\n",
        "                        batch_test_loss += loss.item() * sample[0].size(0)\n",
        "\n",
        "            if phase == 'training':\n",
        "                epoch_train_loss = batch_train_loss / len(dataloaders['training'])\n",
        "                train_epoch_losses.append(epoch_train_loss)\n",
        "            else:\n",
        "                epoch_test_loss = batch_test_loss / len(dataloaders['test'])\n",
        "                test_epoch_losses.append(epoch_test_loss)\n",
        "\n",
        "            batchsummary['epoch'] = epoch\n",
        "\n",
        "            print('{} Loss: {:.4f}'.format(phase, loss))\n",
        "\n",
        "        torch.save(model.state_dict(), f'trained_model_epoch_{epoch+1}.pth')\n",
        "\n",
        "        best_loss = np.max(batchsummary['test_dice_coeff'])\n",
        "        for field in fieldnames[3:]:\n",
        "            batchsummary[field] = np.mean(batchsummary[field])\n",
        "        print(\n",
        "            f'\\t\\t\\t train_dice_coeff: {batchsummary[\"training_dice_coeff\"]}, test_dice_coeff: {batchsummary[\"test_dice_coeff\"]}')\n",
        "\n",
        "    print('Best dice coefficient: {:4f}'.format(best_loss))\n",
        "\n",
        "    return model, train_epoch_losses, test_epoch_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3588fefb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-22T07:29:48.827488Z",
          "iopub.status.busy": "2023-12-22T07:29:48.826806Z",
          "iopub.status.idle": "2023-12-22T15:14:57.070451Z",
          "shell.execute_reply": "2023-12-22T15:14:57.068406Z"
        },
        "papermill": {
          "duration": 27908.298837,
          "end_time": "2023-12-22T15:14:57.106083",
          "exception": false,
          "start_time": "2023-12-22T07:29:48.807246",
          "status": "completed"
        },
        "tags": [],
        "id": "3588fefb"
      },
      "outputs": [],
      "source": [
        "epochs = 80\n",
        "\n",
        "def train():\n",
        "    model = AttentionUNet()\n",
        "    model.load_state_dict(torch.load('/kaggle/input/2d-baseline-3/trained_model.pth'))\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "    criterion = FocalLoss(gamma=2)\n",
        "\n",
        "    trained_model, train_epoch_losses, test_epoch_losses = train_and_test(model, dataloaders, optimizer, criterion, num_epochs=epochs)\n",
        "\n",
        "    return trained_model, train_epoch_losses, test_epoch_losses\n",
        "\n",
        "\n",
        "trained_model, train_epoch_losses, test_epoch_losses = train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91b2e7cb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-22T15:14:57.156030Z",
          "iopub.status.busy": "2023-12-22T15:14:57.155159Z",
          "iopub.status.idle": "2023-12-22T15:14:57.401489Z",
          "shell.execute_reply": "2023-12-22T15:14:57.400532Z"
        },
        "papermill": {
          "duration": 0.274145,
          "end_time": "2023-12-22T15:14:57.403884",
          "exception": false,
          "start_time": "2023-12-22T15:14:57.129739",
          "status": "completed"
        },
        "tags": [],
        "id": "91b2e7cb"
      },
      "outputs": [],
      "source": [
        "torch.save(trained_model.state_dict(), 'trained_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "011cbd4a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-22T15:14:57.454075Z",
          "iopub.status.busy": "2023-12-22T15:14:57.453754Z",
          "iopub.status.idle": "2023-12-22T15:14:57.769595Z",
          "shell.execute_reply": "2023-12-22T15:14:57.768585Z"
        },
        "papermill": {
          "duration": 0.344319,
          "end_time": "2023-12-22T15:14:57.771976",
          "exception": false,
          "start_time": "2023-12-22T15:14:57.427657",
          "status": "completed"
        },
        "tags": [],
        "id": "011cbd4a"
      },
      "outputs": [],
      "source": [
        "train_plot, = plt.plot(range(1, len(train_epoch_losses) + 1), train_epoch_losses, label='train loss')\n",
        "test_plot, = plt.plot(range(1, len(test_epoch_losses) + 1), test_epoch_losses, label='test loss')\n",
        "plt.legend(handles=[train_plot, test_plot])\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Test Loss Over Epochs')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4891507",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-22T15:14:57.822767Z",
          "iopub.status.busy": "2023-12-22T15:14:57.822385Z",
          "iopub.status.idle": "2023-12-22T15:14:58.044798Z",
          "shell.execute_reply": "2023-12-22T15:14:58.043866Z"
        },
        "papermill": {
          "duration": 0.250117,
          "end_time": "2023-12-22T15:14:58.046876",
          "exception": false,
          "start_time": "2023-12-22T15:14:57.796759",
          "status": "completed"
        },
        "tags": [],
        "id": "b4891507"
      },
      "outputs": [],
      "source": [
        "train_plot, = plt.plot(range(len(train_epoch_losses)-15), train_epoch_losses[15:], label='train loss')\n",
        "test_plot, = plt.plot(range(len(test_epoch_losses)-15), test_epoch_losses[15:], label='test loss')\n",
        "plt.legend(handles=[train_plot, test_plot])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "359cf8b0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-22T15:14:58.098935Z",
          "iopub.status.busy": "2023-12-22T15:14:58.098610Z",
          "iopub.status.idle": "2023-12-22T15:14:59.377387Z",
          "shell.execute_reply": "2023-12-22T15:14:59.376334Z"
        },
        "papermill": {
          "duration": 1.308157,
          "end_time": "2023-12-22T15:14:59.379774",
          "exception": false,
          "start_time": "2023-12-22T15:14:58.071617",
          "status": "completed"
        },
        "tags": [],
        "id": "359cf8b0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({'train' : train_epoch_losses, 'test' : test_epoch_losses})\n",
        "df.to_csv('losses.csv', index = False)"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "databundleVersionId": 6962461,
          "sourceId": 61446,
          "sourceType": "competition"
        },
        {
          "sourceId": 155365041,
          "sourceType": "kernelVersion"
        }
      ],
      "dockerImageVersionId": 30588,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 27927.069356,
      "end_time": "2023-12-22T15:15:02.821067",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-12-22T07:29:35.751711",
      "version": "2.4.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}