{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b51dbf4a",
   "metadata": {
    "papermill": {
     "duration": 0.004966,
     "end_time": "2023-12-25T05:06:55.737548",
     "exception": false,
     "start_time": "2023-12-25T05:06:55.732582",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "496bcac5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-25T05:06:55.748703Z",
     "iopub.status.busy": "2023-12-25T05:06:55.747630Z",
     "iopub.status.idle": "2023-12-25T05:07:40.988451Z",
     "shell.execute_reply": "2023-12-25T05:07:40.986663Z"
    },
    "papermill": {
     "duration": 45.25034,
     "end_time": "2023-12-25T05:07:40.992422",
     "exception": false,
     "start_time": "2023-12-25T05:06:55.742082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /kaggle/input/pip-download-for-segmentation-models-pytorch\r\n",
      "Processing /kaggle/input/pip-download-for-segmentation-models-pytorch/segmentation_models_pytorch-0.3.3-py3-none-any.whl\r\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.15.1)\r\n",
      "Processing /kaggle/input/pip-download-for-segmentation-models-pytorch/pretrainedmodels-0.7.4.tar.gz (from segmentation-models-pytorch)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hProcessing /kaggle/input/pip-download-for-segmentation-models-pytorch/efficientnet_pytorch-0.7.1.tar.gz (from segmentation-models-pytorch)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hProcessing /kaggle/input/pip-download-for-segmentation-models-pytorch/timm-0.9.2-py3-none-any.whl (from segmentation-models-pytorch)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (4.66.1)\r\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (10.1.0)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.0.0)\r\n",
      "Processing /kaggle/input/pip-download-for-segmentation-models-pytorch/munch-4.0.0-py2.py3-none-any.whl (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (6.0.1)\r\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.17.3)\r\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.4.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.24.3)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.31.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.12.2)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (4.5.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2023.10.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (21.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.2.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2023.7.22)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (3.0.9)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\r\n",
      "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\r\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=26016c050d498d54b1a548eff81166649ef071d75cbfcc03ec8629a71619bf9a\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/d2/e7/71/a031831a75a14914d29e2f255fcbc113d825ff4762d42f0315\r\n",
      "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60943 sha256=9d3b8c4638972427c803f87c67b3513a3643a1e7780466fd77990409e074a030\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/10/53/cc/d9cbdaa15d821ad4845e69994708dcad78fcddf4c92a753bdf\r\n",
      "Successfully built efficientnet-pytorch pretrainedmodels\r\n",
      "Installing collected packages: munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\r\n",
      "  Attempting uninstall: timm\r\n",
      "    Found existing installation: timm 0.9.10\r\n",
      "    Uninstalling timm-0.9.10:\r\n",
      "      Successfully uninstalled timm-0.9.10\r\n",
      "Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.3 timm-0.9.2\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p /root/.cache/torch/hub/checkpoints/\n",
    "!cp /kaggle/input/se-net-pretrained-imagenet-weights/* /root/.cache/torch/hub/checkpoints/\n",
    "import torch as tc \n",
    "import torch.nn as nn  \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os,sys,cv2\n",
    "from torch.cuda.amp import autocast\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "!python -m pip install --no-index --find-links=/kaggle/input/pip-download-for-segmentation-models-pytorch segmentation-models-pytorch\n",
    "import segmentation_models_pytorch as smp\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.parallel import DataParallel\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087c536b",
   "metadata": {
    "papermill": {
     "duration": 0.008568,
     "end_time": "2023-12-25T05:07:41.009979",
     "exception": false,
     "start_time": "2023-12-25T05:07:41.001411",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e48b383",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-25T05:07:41.033011Z",
     "iopub.status.busy": "2023-12-25T05:07:41.031774Z",
     "iopub.status.idle": "2023-12-25T05:07:41.047054Z",
     "shell.execute_reply": "2023-12-25T05:07:41.045138Z"
    },
    "papermill": {
     "duration": 0.030472,
     "end_time": "2023-12-25T05:07:41.050729",
     "exception": false,
     "start_time": "2023-12-25T05:07:41.020257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # ============== pred target =============\n",
    "    target_size = 1\n",
    "\n",
    "    # ============== model CFG =============\n",
    "    model_name = 'Unet'\n",
    "    backbone = 'se_resnext101_32x4d'\n",
    "\n",
    "    in_chans = 5 # 입력 채널 수\n",
    "    # ============== training CFG =============\n",
    "    image_size = 256\n",
    "    input_size=256\n",
    "    drop_egde_pixel = 0\n",
    "    tile_size = image_size\n",
    "    stride = tile_size // 2\n",
    "    assert stride>drop_egde_pixel # stride가 drop_edge_pixel보다 커야 함\n",
    "\n",
    "    train_batch_size = 16 # 32\n",
    "    valid_batch_size = train_batch_size * 2\n",
    "\n",
    "    epochs = 20  # 에폭 수\n",
    "    lr = 6e-4 # 학습률\n",
    "\n",
    "    # ============== fold =============\n",
    "    valid_id = 1 # 검증 세트 ID\n",
    "\n",
    "\n",
    "    # ============== augmentation =============\n",
    "    train_aug_list = [\n",
    "        A.RandomResizedCrop(\n",
    "            input_size, input_size, scale=(0.8,1.25)),\n",
    "        A.ShiftScaleRotate(p=0.75),\n",
    "        A.OneOf([\n",
    "                A.GaussNoise(var_limit=[10, 50]),\n",
    "                A.GaussianBlur(),\n",
    "                A.MotionBlur(),\n",
    "                ], p=0.4),\n",
    "        A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "    train_aug = A.Compose(train_aug_list)\n",
    "    valid_aug_list = [\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    "    valid_aug = A.Compose(valid_aug_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffb27ea",
   "metadata": {
    "papermill": {
     "duration": 0.008566,
     "end_time": "2023-12-25T05:07:41.068139",
     "exception": false,
     "start_time": "2023-12-25T05:07:41.059573",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb8c6de6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-25T05:07:41.088654Z",
     "iopub.status.busy": "2023-12-25T05:07:41.087558Z",
     "iopub.status.idle": "2023-12-25T05:07:41.096112Z",
     "shell.execute_reply": "2023-12-25T05:07:41.095115Z"
    },
    "papermill": {
     "duration": 0.020997,
     "end_time": "2023-12-25T05:07:41.098221",
     "exception": false,
     "start_time": "2023-12-25T05:07:41.077224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, CFG, weight=None):\n",
    "        super().__init__()\n",
    "        self.CFG = CFG\n",
    "        self.encoder = smp.Unet(\n",
    "            encoder_name=CFG.backbone, \n",
    "            encoder_weights=weight,\n",
    "            in_channels=CFG.in_chans,\n",
    "            classes=CFG.target_size,\n",
    "            activation=None,\n",
    "        )\n",
    "\n",
    "    def forward(self, image):\n",
    "        output = self.encoder(image)\n",
    "        # output = output.squeeze(-1)\n",
    "        return output[:,0]#.sigmoid()\n",
    "\n",
    "\n",
    "def build_model(weight=\"imagenet\"):\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "\n",
    "    print('model_name', CFG.model_name)\n",
    "    print('backbone', CFG.backbone)\n",
    "\n",
    "    model = CustomModel(CFG, weight)\n",
    "\n",
    "    return model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a878560",
   "metadata": {
    "papermill": {
     "duration": 0.006582,
     "end_time": "2023-12-25T05:07:41.111936",
     "exception": false,
     "start_time": "2023-12-25T05:07:41.105354",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d93c685e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-25T05:07:41.128437Z",
     "iopub.status.busy": "2023-12-25T05:07:41.127510Z",
     "iopub.status.idle": "2023-12-25T05:07:41.153217Z",
     "shell.execute_reply": "2023-12-25T05:07:41.152291Z"
    },
    "papermill": {
     "duration": 0.036635,
     "end_time": "2023-12-25T05:07:41.155232",
     "exception": false,
     "start_time": "2023-12-25T05:07:41.118597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def min_max_normalization(x:tc.Tensor)->tc.Tensor:\n",
    "    \"\"\"input.shape=(batch,f1,...)\"\"\"\n",
    "    shape=x.shape # 입력 텐서의 형태를 저장\n",
    "    if x.ndim>2:\n",
    "        x=x.reshape(x.shape[0],-1)  # 입력 텐서의 차원을 하나로 평탄화\n",
    "    \n",
    "    min_=x.min(dim=-1,keepdim=True)[0]\n",
    "    max_=x.max(dim=-1,keepdim=True)[0]\n",
    "    if min_.mean()==0 and max_.mean()==1:\n",
    "        return x.reshape(shape)\n",
    "    \n",
    "    x=(x-min_)/(max_-min_+1e-9) # 픽셀값을 0과 1사이로 조정 , 1e-9는 작은 상수\n",
    "    return x.reshape(shape)\n",
    "\n",
    "class Data_loader(Dataset):\n",
    "    def __init__(self,path,s=\"/images/\"):\n",
    "        self.paths=glob(path+f\"{s}*.tif\")\n",
    "        self.paths.sort()\n",
    "        self.bool=s==\"/labels/\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        img=cv2.imread(self.paths[index],cv2.IMREAD_GRAYSCALE)\n",
    "        # 이미지를 그레이스케일로 읽어옴\n",
    "        img=tc.from_numpy(img)\n",
    "        if self.bool:\n",
    "            img=img.to(tc.bool)\n",
    "        else:\n",
    "            img=img.to(tc.uint8)\n",
    "        return img\n",
    "\n",
    "def load_data(path,s):\n",
    "    data_loader=Data_loader(path,s)\n",
    "    data_loader=DataLoader(data_loader, batch_size=16, num_workers=2) # num_workers : 데이터를 로드하는데 사용할 병렬 작업 수\n",
    "    data=[]\n",
    "    for x in tqdm(data_loader):\n",
    "        data.append(x)\n",
    "    return tc.cat(data,dim=0)\n",
    "\n",
    "\n",
    "\n",
    "def dice_coef(pred:tc.Tensor,target:tc.Tensor,TH=0.5,epsilon=1e-5):\n",
    "    if tc.any(pred<0) or tc.any(pred>1):\n",
    "        pred=pred.sigmoid()\n",
    "    target = target.unsqueeze(1).to(tc.float32)\n",
    "    pred = (pred>TH).to(tc.float32)\n",
    "    inter = (target*pred).sum()\n",
    "    den = target.sum() + pred.sum()\n",
    "    dice = ((2*inter+epsilon)/(den+epsilon)).mean()\n",
    "    return dice\n",
    "\n",
    "    \n",
    "class Kaggld_Dataset(Dataset):\n",
    "    def __init__(self,x:list,y:list,arg=False):\n",
    "        super(Dataset,self).__init__()\n",
    "        self.x=x#list[(C,H,W),...] 이미지 데이터 리스트\n",
    "        self.y=y#list[(C,H,W),...] 레이블 데이터 리스트\n",
    "        self.image_size=CFG.image_size\n",
    "        self.in_chans=CFG.in_chans\n",
    "        self.arg=arg\n",
    "        if arg:\n",
    "            self.transform=CFG.train_aug\n",
    "        else: \n",
    "            self.transform=CFG.valid_aug\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return sum([y.shape[0]-self.in_chans for y in self.y])\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        i=0\n",
    "        for x in self.x:\n",
    "            if index>x.shape[0]-self.in_chans: # 입력 이미지의 시퀀스 또는 프레임수보다 주어진 index가 더 크면 이를 빼고 인덱스를 조정\n",
    "                index-=x.shape[0]-self.in_chans\n",
    "                i+=1\n",
    "            else:\n",
    "                break\n",
    "        x=self.x[i]\n",
    "        y=self.y[i]\n",
    "        \n",
    "        # 이미지와 레이블의 임의의 부분을 추출\n",
    "        x_index=np.random.randint(0,x.shape[1]-self.image_size)\n",
    "        y_index=np.random.randint(0,x.shape[2]-self.image_size)\n",
    "\n",
    "        x=x[index:index+self.in_chans,x_index:x_index+self.image_size,y_index:y_index+self.image_size].to(tc.float32)\n",
    "        y=y[index+self.in_chans//2,x_index:x_index+self.image_size,y_index:y_index+self.image_size].to(tc.float32)\n",
    "\n",
    "        # 데이터 증강 수행\n",
    "        data = self.transform(image=x.numpy().transpose(1,2,0), mask=y.numpy())\n",
    "        x = data['image']\n",
    "        y = data['mask']\n",
    "        # 훈련 중에 추가적인 랜덤변환 수행\n",
    "        if self.arg:\n",
    "            i=np.random.randint(4)\n",
    "            x=x.rot90(i,dims=(1,2))\n",
    "            y=y.rot90(i,dims=(0,1))\n",
    "            for i in range(3):\n",
    "                if np.random.randint(2):\n",
    "                    x=x.flip(dims=(i,))\n",
    "                    if i>=1:\n",
    "                        y=y.flip(dims=(i-1,))\n",
    "        return x,y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651e610b",
   "metadata": {
    "papermill": {
     "duration": 0.006693,
     "end_time": "2023-12-25T05:07:41.168972",
     "exception": false,
     "start_time": "2023-12-25T05:07:41.162279",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59e6c33a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-25T05:07:41.183946Z",
     "iopub.status.busy": "2023-12-25T05:07:41.183589Z",
     "iopub.status.idle": "2023-12-25T05:11:28.255707Z",
     "shell.execute_reply": "2023-12-25T05:11:28.254570Z"
    },
    "papermill": {
     "duration": 227.082461,
     "end_time": "2023-12-25T05:11:28.258383",
     "exception": false,
     "start_time": "2023-12-25T05:07:41.175922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139/139 [01:00<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2217, 1041, 1511])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139/139 [00:26<00:00,  5.26it/s]\n",
      "100%|██████████| 65/65 [00:44<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1035, 1706, 1510])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [00:16<00:00,  4.01it/s]\n",
      "100%|██████████| 143/143 [00:47<00:00,  3.01it/s]\n",
      "100%|██████████| 143/143 [00:21<00:00,  6.52it/s]\n"
     ]
    }
   ],
   "source": [
    "train_x=[]\n",
    "train_y=[]\n",
    "\n",
    "root_path=\"/kaggle/input/blood-vessel-segmentation/\"\n",
    "paths=glob(root_path+\"train/*\")\n",
    "paths.sort()\n",
    "for i,path in enumerate(paths[2:]):#Because the memory is not enough, so I don't use some data.\n",
    "    if path==\"/kaggle/input/blood-vessel-segmentation/train/kidney_3_dense\":\n",
    "        continue\n",
    "    x=load_data(path,\"/images/\")\n",
    "    print(x.shape)\n",
    "    y=load_data(path,\"/labels/\")\n",
    "    train_x.append(x)\n",
    "    train_y.append(y)\n",
    "\n",
    "    #(C,H,W)\n",
    "\n",
    "    #aug\n",
    "    train_x.append(x.permute(1,2,0))\n",
    "    train_y.append(y.permute(1,2,0))\n",
    "    train_x.append(x.permute(2,0,1))\n",
    "    train_y.append(y.permute(2,0,1))\n",
    "\n",
    "val_x=load_data(paths[0],\"/images/\")\n",
    "val_y=load_data(paths[0],\"/labels/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72413136",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-25T05:11:28.356565Z",
     "iopub.status.busy": "2023-12-25T05:11:28.355776Z",
     "iopub.status.idle": "2023-12-25T05:11:32.855855Z",
     "shell.execute_reply": "2023-12-25T05:11:32.854926Z"
    },
    "papermill": {
     "duration": 4.550162,
     "end_time": "2023-12-25T05:11:32.858123",
     "exception": false,
     "start_time": "2023-12-25T05:11:28.307961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name Unet\n",
      "backbone se_resnext101_32x4d\n"
     ]
    }
   ],
   "source": [
    "model=build_model()\n",
    "model=DataParallel(model) # 모델 병렬처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d794f8ca",
   "metadata": {
    "papermill": {
     "duration": 0.044719,
     "end_time": "2023-12-25T05:11:32.948555",
     "exception": false,
     "start_time": "2023-12-25T05:11:32.903836",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f095ee8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-25T05:11:33.083625Z",
     "iopub.status.busy": "2023-12-25T05:11:33.083005Z",
     "iopub.status.idle": "2023-12-25T06:44:48.091084Z",
     "shell.execute_reply": "2023-12-25T06:44:48.089964Z"
    },
    "papermill": {
     "duration": 5597.293364,
     "end_time": "2023-12-25T06:44:50.330489",
     "exception": false,
     "start_time": "2023-12-25T05:11:33.037125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name Unet\n",
      "backbone se_resnext101_32x4d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:0,loss:0.2947,score:0.3261,lr2.9084e-04: 100%|██████████| 562/562 [04:26<00:00,  2.11it/s]\n",
      "val-->loss:0.0627,score:0.4713: 100%|██████████| 143/143 [00:18<00:00,  7.87it/s]\n",
      "epoch:1,loss:0.0253,score:0.6283,lr5.9689e-04: 100%|██████████| 562/562 [04:20<00:00,  2.16it/s]\n",
      "val-->loss:0.0303,score:0.5379: 100%|██████████| 143/143 [00:18<00:00,  7.88it/s]\n",
      "epoch:2,loss:0.0124,score:0.7060,lr5.9664e-04: 100%|██████████| 562/562 [04:20<00:00,  2.15it/s]\n",
      "val-->loss:0.0187,score:0.7160: 100%|██████████| 143/143 [00:18<00:00,  7.85it/s]\n",
      "epoch:3,loss:0.0101,score:0.7362,lr5.8513e-04: 100%|██████████| 562/562 [04:20<00:00,  2.15it/s]\n",
      "val-->loss:0.0171,score:0.7339: 100%|██████████| 143/143 [00:18<00:00,  7.87it/s]\n",
      "epoch:4,loss:0.0095,score:0.7475,lr5.6577e-04: 100%|██████████| 562/562 [04:20<00:00,  2.16it/s]\n",
      "val-->loss:0.0146,score:0.7724: 100%|██████████| 143/143 [00:18<00:00,  7.91it/s]\n",
      "epoch:5,loss:0.0086,score:0.7932,lr5.3909e-04: 100%|██████████| 562/562 [04:20<00:00,  2.16it/s]\n",
      "val-->loss:0.0132,score:0.8282: 100%|██████████| 143/143 [00:18<00:00,  7.92it/s]\n",
      "epoch:6,loss:0.0086,score:0.7927,lr5.0581e-04: 100%|██████████| 562/562 [04:20<00:00,  2.16it/s]\n",
      "val-->loss:0.0159,score:0.7867: 100%|██████████| 143/143 [00:18<00:00,  7.92it/s]\n",
      "epoch:7,loss:0.0087,score:0.7832,lr4.6686e-04: 100%|██████████| 562/562 [04:20<00:00,  2.16it/s]\n",
      "val-->loss:0.0128,score:0.8258: 100%|██████████| 143/143 [00:18<00:00,  7.92it/s]\n",
      "epoch:8,loss:0.0076,score:0.7917,lr4.2331e-04: 100%|██████████| 562/562 [04:20<00:00,  2.16it/s]\n",
      "val-->loss:0.0129,score:0.8104: 100%|██████████| 143/143 [00:18<00:00,  7.90it/s]\n",
      "epoch:9,loss:0.0074,score:0.8101,lr3.7636e-04: 100%|██████████| 562/562 [04:20<00:00,  2.16it/s]\n",
      "val-->loss:0.0147,score:0.8212: 100%|██████████| 143/143 [00:18<00:00,  7.85it/s]\n",
      "epoch:10,loss:0.0078,score:0.8167,lr3.2730e-04: 100%|██████████| 562/562 [04:20<00:00,  2.16it/s]\n",
      "val-->loss:0.0137,score:0.7932: 100%|██████████| 143/143 [00:18<00:00,  7.84it/s]\n",
      "epoch:11,loss:0.0075,score:0.8035,lr2.7749e-04: 100%|██████████| 562/562 [04:20<00:00,  2.16it/s]\n",
      "val-->loss:0.0172,score:0.7675: 100%|██████████| 143/143 [00:18<00:00,  7.89it/s]\n",
      "epoch:12,loss:0.0073,score:0.8264,lr2.2831e-04: 100%|██████████| 562/562 [04:20<00:00,  2.16it/s]\n",
      "val-->loss:0.0148,score:0.8207: 100%|██████████| 143/143 [00:18<00:00,  7.92it/s]\n",
      "epoch:13,loss:0.0064,score:0.8328,lr1.8110e-04: 100%|██████████| 562/562 [04:20<00:00,  2.15it/s]\n",
      "val-->loss:0.0127,score:0.8602: 100%|██████████| 143/143 [00:18<00:00,  7.91it/s]\n",
      "epoch:14,loss:0.0069,score:0.8282,lr1.3716e-04: 100%|██████████| 562/562 [04:20<00:00,  2.15it/s]\n",
      "val-->loss:0.0132,score:0.8520: 100%|██████████| 143/143 [00:18<00:00,  7.91it/s]\n",
      "epoch:15,loss:0.0063,score:0.8518,lr9.7719e-05: 100%|██████████| 562/562 [04:21<00:00,  2.15it/s]\n",
      "val-->loss:0.0150,score:0.8112: 100%|██████████| 143/143 [00:18<00:00,  7.85it/s]\n",
      "epoch:16,loss:0.0064,score:0.8481,lr6.3852e-05: 100%|██████████| 562/562 [04:21<00:00,  2.15it/s]\n",
      "val-->loss:0.0114,score:0.8520: 100%|██████████| 143/143 [00:18<00:00,  7.85it/s]\n",
      "epoch:17,loss:0.0059,score:0.8459,lr3.6493e-05: 100%|██████████| 562/562 [04:21<00:00,  2.15it/s]\n",
      "val-->loss:0.0134,score:0.8610: 100%|██████████| 143/143 [00:18<00:00,  7.84it/s]\n",
      "epoch:18,loss:0.0057,score:0.8505,lr1.6399e-05: 100%|██████████| 562/562 [04:21<00:00,  2.15it/s]\n",
      "val-->loss:0.0127,score:0.8953: 100%|██████████| 143/143 [00:18<00:00,  7.85it/s]\n",
      "epoch:19,loss:0.0061,score:0.8597,lr4.1226e-06: 100%|██████████| 562/562 [04:21<00:00,  2.15it/s]\n",
      "val-->loss:0.0115,score:0.8891: 100%|██████████| 143/143 [00:18<00:00,  7.90it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset=Kaggld_Dataset(train_x,train_y,arg=True)\n",
    "train_dataset = DataLoader(train_dataset, batch_size=16, num_workers=2, shuffle=True, pin_memory=True)\n",
    "val_dataset=Kaggld_Dataset([val_x],[val_y])\n",
    "val_dataset = DataLoader(val_dataset, batch_size=16, num_workers=2, shuffle=False, pin_memory=True)\n",
    "\n",
    "model=build_model()\n",
    "model=DataParallel(model)\n",
    "\n",
    "loss_fn=nn.BCEWithLogitsLoss()\n",
    "optimizer=tc.optim.AdamW(model.parameters(),lr=CFG.lr)\n",
    "scaler=tc.cuda.amp.GradScaler()\n",
    "scheduler = tc.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=CFG.lr,\n",
    "                                                steps_per_epoch=len(train_dataset), epochs=CFG.epochs+1,\n",
    "                                                pct_start=0.1,) # 학습률 스케줄링\n",
    "for epoch in range(CFG.epochs):\n",
    "    time=tqdm(range(len(train_dataset)))\n",
    "    losss=0\n",
    "    scores=0\n",
    "    a=[]\n",
    "    b=[]\n",
    "    c=[]\n",
    "    d=[]\n",
    "    for i,(x,y) in enumerate(train_dataset):\n",
    "        x=x.cuda()\n",
    "        y=y.cuda()\n",
    "        x=min_max_normalization(x)\n",
    "\n",
    "        with autocast(): # 연산 16비트 부동소수점형태\n",
    "            pred=model(x)\n",
    "            loss=loss_fn(pred,y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        scheduler.step()\n",
    "        score=dice_coef(pred.detach(),y) # dice coefficient 계산\n",
    "        losss=(losss*i+loss.item())/(i+1) # 현재까지 평균 손실 업데이트\n",
    "        scores=(scores*i+score)/(i+1) # 현재까지 평균 성능 지표 업데이트\n",
    "        a.append(losss)\n",
    "        b.append(scores)\n",
    "        time.set_description(f\"epoch:{epoch},loss:{losss:.4f},score:{scores:.4f},lr{optimizer.param_groups[0]['lr']:.4e}\")\n",
    "        time.update()\n",
    "        del loss,pred\n",
    "    time.close()\n",
    "    val_losss=0\n",
    "    val_scores=0\n",
    "    time=tqdm(range(len(val_dataset)))\n",
    "    for i,(x,y) in enumerate(val_dataset):\n",
    "        x=x.cuda()\n",
    "        y=y.cuda()\n",
    "        x=min_max_normalization(x)\n",
    "\n",
    "        with autocast():\n",
    "            with tc.no_grad():\n",
    "                pred=model(x)\n",
    "                loss=loss_fn(pred,y)\n",
    "        score=dice_coef(pred.detach(),y)\n",
    "        val_losss=(val_losss*i+loss.item())/(i+1)\n",
    "        val_scores=(val_scores*i+score)/(i+1)\n",
    "        c.append(val_losss)\n",
    "        d.append(val_scores)\n",
    "        time.set_description(f\"val-->loss:{val_losss:.4f},score:{val_scores:.4f}\")\n",
    "        time.update()\n",
    "\n",
    "    time.close()\n",
    "    tc.save(model.state_dict(),f\"./{CFG.backbone}_{epoch}_loss{losss:.2f}_score{scores:.2f}_val_loss{val_losss:.2f}_val_score{val_scores:.2f}.pt\")\n",
    "\n",
    "time.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d33bb122",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-25T06:44:55.065938Z",
     "iopub.status.busy": "2023-12-25T06:44:55.065155Z",
     "iopub.status.idle": "2023-12-25T06:44:55.072821Z",
     "shell.execute_reply": "2023-12-25T06:44:55.071917Z"
    },
    "papermill": {
     "duration": 2.376491,
     "end_time": "2023-12-25T06:44:55.074804",
     "exception": false,
     "start_time": "2023-12-25T06:44:52.698313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "562"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 6962461,
     "sourceId": 61446,
     "sourceType": "competition"
    },
    {
     "datasetId": 1074109,
     "sourceId": 1807973,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 150248402,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5888.691139,
   "end_time": "2023-12-25T06:45:01.068984",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-25T05:06:52.377845",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
