# 감성 분석을 통한 긍정적인 말하기의 실천 

NLP 분반에서 학습한 감성 분석을 통해 다른 사람과 채팅을 할 때 특정 채팅 내용이 긍정적인지 부정적인지를 파악하는 모델을 (BERT)를 기반으로 개발.

## 사용된 데이터

감성 대화 말뭉치: https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=86

네이버 영화 리뷰 감성 데이터: https://github.com/e9t/nsmc

## 프로젝트 목적

최근 대화 트렌드는 온라인 대화이다. 하지만, 온라인 대화는 말투, 몸짓 등의 반언어적 표현과 비언어적 표현이 존재하지 않고 오로지 언어적인 텍스트 표현의 의존하기 때문에 오해가 발생하기 쉽다. 그래서, 온라인 대화로 인한 오해와 그로 인한 갈등이 빈번히 발생 하고 있다. 이에 대한 해결책은 온라인 상으로는 평소보다 긍정적으로 대화하는 것이다. 직접 오프라인 상으로 말했을때는 아무 문제 없는 말이, 온라인 상에서 텍스트로만 보여지면 부정적인 것으로 받아 들여질 수 있기 때문이다. 하지만, 무엇이 긍정적, 부정적으로 보일 지 메시지를 보내는 사람이 그때 그때 판별하기에는 무리가 있다. 따라서, 해당 메시지가 긍정적으로 보일지, 부정적으로 보일지 자동으로 판명해주는 감성 분석 모델을 구축하여, 온라인 대화 상에서 갈등이 발생하는 현상을 완화하고자 한다.

## 결론

모델의 정확도는 꽤 높지만, 데이터 불균형으로 인해 부정으로 판정하는 데이터의 비율이 더 많다. 이러한 바이어스는 물론 해결하면 좋지만, 이 모델의 목적성을 고려하였을때, 긍정보다 부정을 정확히 판단하는 것이 중요하다. 긍정을 부정으로 판단하면 메시지를 보내기 전에 다시 수정할 수 있어 문제가 발생하지 않지만, 부정을 긍정으로 판명하면 자신이 쓴 메시지의 문제점을 제대로 파악하지 못 한 채로 그대로 전송할 것이기 때문이다. 이를 고려하면 데이터의 불균형으로 인해 부정 판정을 더 많이 내는 우리의 모델이 오히려 장점을 발휘할 수 있다. 하지만, 데이터 부족으로 인해 아직 다양한 대화 스타일이나 신조어 등은 이해하지 못하며, 이 부분은 개선이 필요하다.


## 추가적인 개선 제안

추가적인 실제 채팅 데이터를 라벨링 하여 학습하면 기존 데이터에 없는 단어를 넣었을 때 무조건 부정으로 판명하는 현상이 개선될 것으로 전망.
긍정 데이터가 부족하여 부정으로 판정이 쏠리는 현상도 추가적인 데이터의 학습으로 극복 가능할 것이라 전망함.
부정으로 판별하는 threshold 를 조정하여 긍정 판명의 비율을 더 높게 만드는 것도 개선 방안 중 하나.
